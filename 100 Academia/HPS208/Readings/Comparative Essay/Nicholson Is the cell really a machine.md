NICHOLSON 2019 IS THE CELL REALLY A MACHINE

1. Introduction: The Machine Conception of the Cell  Over the past half a century, molecular biology has generated vast amounts of knowledge at a rate that is surely unprecedented in the history of science. However, our progress in translating this ever-growing repository of information into a deeper theoretical understanding of what living systems are and how they function as coordinated wholes has been far less impressive. Now it may be that this is simply a reflection of the extraordinary complexity of the cell, and that it is only a matter of time before all cellular components are characterized and all of their interconnections are fully mapped out, at which point we will finally have a total grasp of the internal workings of the cell. Alternatively, it is possible that the  ∗ Correspondence to: Konrad Lorenz Institute for Evolution and Cognition Research, Martinstraße 12, Klosterneuburg, 3400, Austria. E-mail address: <dan.j.nicholson@gmail.com>  problem lies not so much in the complexity of the cell as in the interpretive framework—the theoretical presuppositions, conceptual categories, and explanatory models—routinely used to make sense of this complexity. This paper explores this second possibility. The main interpretive framework in molecular biology is mechanicism, a highly influential research program with many forms and incarnations that can be traced all the way back to the natural philosophy that gave rise to the Scientific Revolution (Hall, 1969; Nicholson, 2012; Loison, 2015)1. Modern proponents of mechanicism conceive of the cell as an intricate piece of machinery whose organization reflects a pre-existing design, whose structure is wholly intelligible in reductionistic terms, and whose operation is governed by deterministic laws, rendering its behaviour predictable and controllable—at least in principle. I shall hereafter refer to this pivotal mechanicist notion as the machine conception of the cell (MCC).  The MCC long predates the rise of molecular biology—its history runs parallel to that of mechanicism, which is why one can find rudimentary expressions of the MCC dating back to the seventeenth century, when analogies between machines and organisms first began to acquire currency. Malpighi, one of the founders of microscopical anatomy, attributed the bodily functions of animals and plants to “a very large number of machines, which are of necessity made up of extremely minute parts [...] invisible to the naked eye” (Malpighi, quoted in Piccolino, 2000, p. 149). In a similar vein, Leibniz, the early modern natural philosopher, characterized organisms as machines of divine origin, which are hierarchically composed of ever-smaller machines ad infinitum. He contrasted organisms to machines of human origin, whose component parts are not themselves also machines in their own right (Smith, 2011). By the turn of the twentieth century, the cell was being variously characterized as “a little engine with admirably adapted parts” (Conn, 1899, p. 126), a “chemical machine” capable of “automatically developing, preserving, and reproducing [itself]” (Loeb, 1906, p. 1), and “a battery, with a series of resistances and condensers, made up of conductors and dielectrics” (Matthews, 1924, p. 15). But most influential of all was the understanding of the cell as a “small chemical laboratory” (Hertwig, 1895, p. 126) or a miniature factory, with proteins and other macromolecules arranged like machine tools on an assembly line (Reynolds, 2007, 2018). Following the Second World War, the pioneering ideas of cybernetics, information theory, and computer science captured the imagination of biologists, providing a new vision of the MCC that was translated into a highly successful experimental research program, which came to be known as ‘molecular biology’ (Keller, 1995; Morange, 1998; Kay, 2000). At its core was the idea of the computer, which, by introducing the conceptual distinction between ‘software’ and ‘hardware’, directed the attention of researchers to the nature and coding of the genetic instructions (the software) and to the mechanisms by which these are implemented by the cell’s macromolecular components (the hardware). Early molecular biologists openly conjectured about the structure and function of the cell along these lines, deliberately transgressing the boundaries between the technological and the biological, as the following excerpt from a paper published in 1962 illustrates:  Taking then, as an engineering definition of a living cell, ‘A completely automatic factory for fabricating automatic factories like itself’, we may profitably consider what components might be found in such a system. Passing over such trivia as a power station for utilizing whatever energy source might be available, it is clear that a large computer would be the control mechanism at the centre of our design. In its store would be an encyclopaedia of programmes which would give the proper response to all possible sets of external circumstances, and these would be activated by input devices which would record the external conditions and the supply position. Other input channels would monitor the progress of the various factory processes, forming the feedback loops which are essential to control mechanisms. Output from the computer would go [...] to a set of automatic machine tools which would perform the various operations required for construction of a duplicate factory. Here the complex task of converting the information stored in the computer into solid matter would be performed. (Blow, 1962, p. 177)  It is quite remarkable to observe that, despite the enormous empirical advances that have been made since 1962, our basic theoretical picture of the cell has remained essentially unchanged (see, e.g., Bray, 2009; Danchin, 2009). The standard view nowadays is that the cell coordinates its functions by virtue of a ‘genetic program’ encoded in the DNA that directs and controls the expression of a specific set of RNAs and proteins, which assemble deterministically into stable ‘molecular machines’ that reliably and efficiently  execute predetermined operations according to the mechanisms of cell division, endocytosis, signal transduction, etc. Machine analogies and metaphorical references to ‘locks’, ‘keys’, ‘gates’, ‘pumps’, ‘motors’, and ‘engines’ continue to pervade the technical literature (e.g. Piccolino, 2000; Frank, 2011), as does talk of the ‘machinery’ (e.g. Goodsell, 2009) and ‘circuitry’ (e.g. Alon, 2007) that underlies the cellular organization. The MCC itself is seldom explicitly defended; it has become so engrained in our minds that we simply take it for granted. But why have we relied so heavily on machine metaphors to ground our theoretical understanding of living systems? What is so special about machines that make them such apposite analogues for thinking about cells? Although there are many different kinds of machines, a machine can be characterized in very general terms as a device with fixed interacting parts that operate in a coordinated fashion to produce a predetermined outcome. More specifically, one can identify four distinctive properties of machines that are particularly relevant in contemporary formulations of the MCC. First, machines can be described in terms of a list of parts and a blueprint indicating how those parts fit together, meaning that someone who has never seen a particular kind of machine should in principle be able to assemble any number of copies—each virtually identical in appearance and performance—provided they can consult the machine’s design specifications. Second, as machines are designed to perform highly specific functions, their operation is tightly constrained, which is why it is possible to predict and control their behaviour. Third, machines are highly efficient in what they do because they always follow the exact same sequence of steps in every cycle of their operation. And fourth, the operation of machines is not continuous; their functioning can be interrupted and their parts examined without thereby jeopardizing their structural integrity. The first and fourth of these characteristics account for why the MCC justifies the belief in the sufficiency of reductionistic explanations of cellular phenomena, whereas the second and third show why the MCC provides support for a deterministic view of cellular processes. In recent years, however, the MCC has come under attack from various fronts. Ironically, the very successes of molecular biology that were instigated by mechanicism have resulted in the accumulation of experimental data that are difficult to assimilate within its interpretive framework. As a result, critical reviews have begun to appear that explicitly challenge the reductionistic and deterministic presuppositions of mechanicism and question the coherence of the familiar clockwork image of the cell. Notable examples include Kirschner et al. (2000), Astumian (2001), Woese (2004), Cornish-Bowden (2006), Longo and Tendero (2007), Karsenti (2008), Huang (2009), Mayer et al. (2009), Kupiec (2010), Moore (2012), Bizzarri et al. (2013), Talbott (2013), Heams (2014), Longo and Montévil (2014), Soto and Sonnenschein (2018), and a series of articles by Kurakin (2005, 2006, 2009, 2010). Drawing and building on this burgeoning body of literature, the aim of this paper is to establish the inadequacy of the MCC. From a theoretical perspective, the MCC offers a poor and rather misleading representation of biological reality—or so I will argue2. The MCC fails to make appropriate sense of cellular phenomena for two basic reasons. The first has to do with the fact that cells, unlike machines, are self-organizing, fluid systems that maintain themselves in a steady state far from thermodynamic equilibrium by continuously exchanging energy and matter with their surroundings. And the second has to do with the fact that by virtue of their microscopic size, cells (and their molecular constituents, even more so) are subject to very different physical conditions compared to macroscopic objects, like machines. Although both of these facts are incontrovertible—indeed, they may strike some readers as painfully obvious—the theoretical implications they have for our understanding of life are far from familiar, and it is these implications that shall be concerning me here. What I will contend is that they lead to a conception of the cell that is completely at odds with the mechanicist, reductionistic, and deterministic view that was championed by the founding fathers of molecular biology, such as Monod in his hugely influential Chance and Necessity (Monod, 1972), quoted in the epigraph of this paper. If the facts that underlie the inadequacy of the MCC really are indisputable, why has it taken us so long to start taking serious notice of them? I suspect that part of the answer has to do with the resistance that many biologists intuitively feel towards denunciations of mechanicism. Perceived inconsistencies and contradictions in the established paradigm are often downplayed—or dismissed altogether—in order to safeguard the familiar assumptions that the research community works under. But an even more important factor, I believe, is that we have been blinded by traditional biochemical and biophysical methods. Until relatively recently, it was only possible to examine the cell’s interior with crude in vitro techniques, looking at average behaviours of large populations of macromolecules under conditions usually remote from those existing in the cell. However, the introduction of novel methods capable of tracking and manipulating individual molecules within cells has allowed us to observe for the first time the real-time dynamics of biological macromolecules and the surprisingly wide range of behavioural repertoires they exhibit in in vivo conditions (Zlatanova and van Holde, 2006; Xie et al., 2008; Tinoco and Gonzalez, 2011). As I will discuss in more detail later, single-molecule studies are yielding results not anticipated by the use of populationaveraged methods. These results are bringing about a radical shift in how we think about the cell, replacing a mechanical, neatly ordered, rigid picture with one that is inherently stochastic, more plastic, and less predictable. What we are witnessing, in effect, is a conceptual revolution being triggered by a methodological revolution. Despite the historical predominance of mechanicism, a new interpretive framework is now required to understand what our recent findings are telling us about the nature of the cell. This framework is already arising, as more molecular biologists are becoming aware of the numerous problems plaguing the MCC. This paper will examine in detail four specific domains of research where the incompatibilities with the MCC are becoming particularly pronounced. The first is the study of the cellular architecture, which in line with the MCC has long been construed as a static, highly ordered structure. The second is the study of protein complexes, which have generally been characterized as remarkably specialized, exquisitely designed molecular machines. The third is the study of intracellular transport, which has tended to be explained in terms of miniature engines propelled by mechanical forces. And the fourth is the study of cellular behaviour, which has long been assumed to be governed by a deterministic program encoded in the genome. Increasingly, all of these mechanicist interpretations are being called into question, and a fundamentally different conception of the cell is emerging. As I will show, according to this alternative view, the cellular architecture is regarded as a fluid, self-organizing process; protein complexes are considered to be transient, pleomorphic ensembles; intracellular transport is deemed to result from the harnessing of Brownian motion; and cellular behaviour is viewed as a probabilistic affair, subject to constant stochastic fluctuations. Taken together, these four case studies will illustrate how a rejection of the MCC—along with the mechanicist assumptions that underlie it—is contributing to the development of a more theoretically compelling picture of the cell.  2. Cellular Architecture: Static Structure or Stabilized Process?  Much of what we know about the cell’s organization derives from snapshots of fixed, stained, or desiccated biological samples obtained by conventional microscopy techniques. A representative example is shown in Fig. 1. Historically, the interpretation of images of this kind naturally led to an understanding of the internal architecture of the cell in terms of clearly delineated, neatly compartmentalized structures that closely resemble machineries. These permanent structures were eventually assigned functions to make sense of their role in the overall economy of the cell, which in accordance with the MCC was viewed as a factory with highly specialized compartments. But how are these structures that constitute the cellular architecture formed and maintained? What is it that determines their different shapes and sizes, as well as their respective locations and functions in the cell? For decades, the basis for our understanding of macromolecular order was the principle of self-assembly (Kushner, 1969; Inouie, 1982; Whitesides and Grzybowski, 2002). Self-assembly involves the physical association of molecules into a static equilibrium structure in the absence of an external energy source. It is driven by local stereospecific interactions between the aggregating ‘building blocks’, which remain unchanged throughout the process. As the properties of the resulting structure are determined by the properties of its parts, self-assembly can be regarded as “an extension of the central dogma of molecular biology, bringing us from the realm of linear information to the realm of protein assemblies” (Kirschner et al., 2000, p. 80). Classical, wellstudied examples of self-assembly include viral capsid formation (Caspar and Klug, 1962) and ribosome biogenesis (Nomura, 1973). However, self-assembly is not the only theoretical principle that can be invoked to explain the spontaneous generation of macromolecular order. There is also the principle of self-organization (Nicolis and Prigogine, 1977; Kauffman, 1993; Karsenti, 2008). Self-organization refers to the collective behaviour of molecules when these interact nonlinearly to generate a dynamic far-fromequilibrium structure (sometimes called a ‘dissipative structure’), which maintains itself in a low-entropic ‘steady state’ by constantly expending energy and exchanging matter with its surroundings. So, while self-assembled systems are closed, as their material constitution is conserved, self-organizing ones are open, as they rely for their preservation on the continuous replenishment of the material that composes them. Of course, we have known for a long time that self-organization is essential for living systems, given that the cell as a wholehow ever else one may wish to describe it—is, thermodynamically speaking, a far-from-equilibrium dissipative structure: in the absence of a steady supply of energy, it reaches equilibrium and dies. Nevertheless, it has proven surprisingly difficult to identify particular instances of self-organization inside the cell. This is due to the fact that self-assembly and self-organization tend to lead to similar observable patterns, albeit through totally different means. Specifically, both generate stable structures; the difference being that those generated by the former exhibit static stability whereas those generated by the latter exhibit dynamic stability (sometimes referred to as ‘meta-stability’). The problem remained that conventional microscopy methods prevented us from distinguishing them. Recent technological innovations have changed all of this. The development of in vivo microscopy techniques using geneticallyencoded fluorescent tags of individual molecules has provided new insights into the spatiotemporal configuration of the cell. Perhaps the most surprising discovery that has emerged from these studies is the unexpectedly high degree of dynamism observed for a wide range of macromolecular structures. It appears that many—perhaps most—subcellular compartments are more appropriately described as dynamic self-organizing steady states than as static self-assembling machineries. The molecular constituents of the cell, it turns out, have a tendency to spontaneously selforganize into morphologically and functionally distinct organizations through inherently stochastic interactions. These transient meta-stable systems are sustained by the incessant flow of energy and matter passing through them, with their respective components displaying different recruitment probabilities, residence times, and turnover rates (Misteli, 2001a; Kurakin, 2009). Let me now discuss some specific examples of intracellular entities that are currently being completely reconceptualized as a result of recent empirical findings (prompted by the use of new methods). The mitotic spindle of eukaryotic cells is one such example. The spindle is an ordered array of microtubules, associated proteins, and chromosomes that forms during cell division, and which distributes the duplicated genetic material to the daughter cells with stunning precision. Owing to its remarkably stable—almost crystalline—appearance in cross-sections of cells undergoing mitosis, the mitotic spindle is often characterized as “a fascinating protein machine” (Mogilner et al., 2006, p. 88) capable of assembling and disassembling according to genetically encoded instructions. However, recent research has shown that the mitotic spindle is actually a self-organizing system, displaying high degrees of flexibility and robustness (Nédélec et al., 2003; Pavin and Toli  ́c, 2016). Architecturally speaking, the microtubules that compose the mitotic spindle are constantly polymerizing and depolymerizing, repeatedly undergoing cycles of GTP hydrolysis to maintain it in a steady state far from equilibrium. As a consequence of these findings,  The traditional view of the mitotic spindle apparatus as a molecular machine which is built through a defined irreversible set of instructions is gradually being replaced. It can instead be envisaged as a self-regulating dynamic structure where multiple pathways of MT [microtubule] generation are spatially and temporally controlled and integrated, constantly ‘talking’ to one another and modifying the behaviour of their MTs in order to  maintain a flexible yet robust steady-state spindle. (Duncan and Wakefield, 2011, p. 330)  It has further been suggested that not only the mitotic spindle, but the entire cytoskeleton is better characterized as a meta-stable flux dynamically responding to changes in its environment than as a static macromolecular construction. “Despite the connotations of the word ‘skeleton’”, Fletcher and Mullins (2010, p. 485) write, “the cytoskeleton is not a fixed structure whose function can be understood in isolation. Rather, it is a dynamic and adaptive structure whose component polymers and regulatory proteins are in constant flux”. Self-organization appears to be similarly crucial for intracellular membrane compartments, such as those involved in the secretory transport pathway, in which proteins targeted to the cell’s exterior are transported from the endoplasmic reticulum through the Golgi complex to the plasma membrane. Although the compartments of this pathway have traditionally been regarded as static structures, the recent tracking of resident and cargo molecules through the pathway using in vivo microscopy has revealed that they are in fact constantly exchanging material (Lippincott-Schwartz et al., 2000). The Golgi complex, for instance, resembles the mitotic spindle in that its stability is a consequence of the balanced turnover of the molecules that flow through it. Given its fluid nature, its architecture can be modified by manipulating the influx and efflux of material passing through its component cisternae. We now know that inhibition of traffic from the endoplasmic reticulum leads to the dispersion of the Golgi complex into small vesicles, whereas blocking the transport of vesicles that bud from it results in its enlargement. Although there is still considerable disagreement over how the actual traffic occurs—specifically over whether the Golgi cisternae themselves progress or mature along the pathway or if it is only their cargo that gets transported (see Glick and Luini, 2011)—what seems clear is that the Golgi complex is a selforganizing steady-state organelle (Tachikawa and Mochizuki, 2017). More broadly, live imaging techniques are unveiling the striking dynamicity that underlies the stability of intracellular membrane compartments of both exocytotic and endocytotic pathways (Kerr and Teasdale, 2014). Our understanding of the eukaryotic cell nucleus is also becoming radically transformed. Far from being the static, crowded, gel-like structure described in textbooks, the nucleus is extremely dynamic and surprisingly fluid. Most of its proteins are highly mobile, stochastically moving about the nucleoplasmic space contingently interacting with one another and participating in different nuclear functions, such as chromatin remodelling, transcriptional activation, ribosomal RNA processing, and DNA repair. The dynamic interplay between nuclear proteins results in an everchanging, yet globally stable architecture within which nuclear processes take place (Misteli, 2001b; Janicki and Spector, 2003). The nuclear architecture includes a number of morphologically and functionally distinct compartments, such as nucleoli, Cajal bodies, and perinuclear specks, that are maintained in a state of “perpetual flux” (Misteli, 2001b, p. 844) by the constant exchange of their resident proteins, which also transiently associate with the chromatin. The latest research on these subnuclear, membraneless organelles strongly suggests that they are better conceived as liquid-like droplets than as solid, core-shell structures: they have a spherical shape, they fuse together, and their molecular constituents are constantly undergoing fluid internal rearrangements (Brangwynne et al., 2011; Shin and Brangwynne, 2017). In addition to its instrumental role in generating and maintaining many organelles, recent studies suggest that self-organization is involved in some of the cell’s most essential processes, including metabolism (De la Fuente et al., 2008), genome organization (Misteli, 2009), cell division (Loose et al., 2008), and cell differentiation (Woodford and Zandstra, 2012). The self-organizing nature of the cellular architecture has far reaching theoretical consequences. Most fundamentally, it leads to a view of the cell that is completely at odds with the MCC. For one thing, it dispels the notion that the ‘information’ that specifies the spatial organization of the cell is somehow encoded in the genome. Strictly speaking, there is no genetic blueprint for the cellular architecture. Self-organization generates order in the absence of an external template or global plan. Genes specify only the primary sequence of macromolecules; the architecture of the cell, for the most part, arises from the interactions of numerous gene products with other cellular components. Genes are important, to be sure, but they do not set in motion a unique chain of events that produces the organization of the cell, as the use of the term ‘information’ sometimes misleadingly suggests. Rather, gene products are released into a cellular milieu that already possesses spatial structure, and they exert their influence under the physical constraints of the existing order—much of which is shaped by pre-existing self-organizing processes (Harold, 2005; Rafelski and Marshall, 2008). In contrast to a machine, in which a fixed architecture performs a predetermined function, a cell is continuously transforming its internal architecture (by modifying the exquisitely regulated balance between the inflow and outflow of its molecular constituents) in order to keep up with its ever-changing functional needs. Cellular structures showcase what Dumont and Prakash (2014) appropriately refer to as ‘emergent mechanics’, which cannot be predicted from knowledge of their parts. The disparity with the mechanics of machines is all too evident, as the authors themselves explicitly acknowledge:  Unlike the engineered macroscopic structures that we commonly build, biological structures are dynamic and selforganize: they sculpt themselves and change their own architecture, and they have structural building blocks that [...] constantly come on and off. A description of such structures defies current traditional mechanical frameworks. (Dumont and Prakash, 2014, p. 3461)  Indeed, no machine self-organizes by autonomously exchanging its material constitution in order to maintain its architecture in a dynamic steady state, yet this is precisely what happens in every cell. But why do cells favour self-organization over self-assembly as the main mechanism for creating their architecture? Would it not make more sense for a cell to build static, equilibrium structures that do not require a constant expenditure of energy to maintain them? Although self-assembly is a more economical and efficient means of producing durable macromolecular structures of great complexity (the viral capsid is a conspicuous example), the resulting structures lack morphological flexibility and do not lend themselves easily to modifications. The advantage of a self-organizing architecture, despite its huge energetic cost, is that it confers a great deal of plasticity without compromising on stability. It allows cells to respond rapidly and adaptively to external perturbations and other critical events that would otherwise jeopardize their systemic integrity. Overall, recent research on the cellular architecture demands that we look more carefully at what we have previously assumed were well-defined structures and reconsider them as stabilized processes. Because processes are temporally extended, it follows that they can only be understood by giving time due consideration. And herein lies the problem: the methods traditionally used to probe the interior of the cell conceal the dynamic nature of its architecture because they have to incapacitate it in order to render it visible. Yet to study a cell frozen in time is already to approach it artificially as a static, machine-like object, rather than as the fluid system that it is in reality (Nicholson, 2018). The structure of a machine, after all, can be grasped in abstraction from time (as it is not constantly changing), whereas the structure of, say, a whirlpool or a stream cannot. This explains why, when we have started using techniques that allow us to examine the cellular architecture in real time, we have found that many of the cell’s compartments and organelles are not fixed machineries at all, but stable macromolecular fluxes. More broadly, the transition from a structural to a processual conception of the cellular architecture implies shifting our attention from matter to form. Due to its dynamic nature, what persists in a cell over time is its form, not its matter: the individual molecules that make up a cell come and go, but its overarching organization remains. Accordingly, if we are to grasp how a cell operates, mapping out the network of spatial and temporal relations that exist between its parts is as, if not more, important than characterizing the parts themselves. The need to adopt a non-reductionist stance is further intensified when we bear in mind that self-organizing processes—which, as I have shown, underlie much of the cellular architecture—force us to focus on systemic patterns and collective behaviours, rather than on the properties and structures of single molecules (which would suffice as an approach if the cell was primarily self-assembling and its order was ultimately encoded in the DNA).


EXCLUDED SOME STUFF

6. Conclusions: Towards a New View of the Cell  I have argued in this paper that molecular biology is currently undergoing a fundamental shift in its theoretical conceptualization of the cell. The conventional mechanical, reductionistic, and deterministic view is gradually giving way to an understanding of the cell that emphasizes its fluidity, plasticity, and stochasticity. Faced with the formidable task of interpreting the vast and ever-growing amount of experimental data that continues to get published, explanatory appeals to engineering notions of design, programs, and circuits are increasingly being replaced by recourses to the physical principles of non-equilibrium thermodynamics and complexity theory. Cells are empirically revealing themselves to be inherently dynamic, self-organizing systems that respond stochastically and nonlinearly to environmental stimuli. The inescapable conclusion that follows from the analysis I have presented is that the cell can no longer be unproblematically conceptualized as a machine5. Over the course of the paper, it has  5 Note that this conclusion does not imply that every entity or process within the cell is being (or needs to be) reconceptualized. To be clear, the thesis I have sought to defend is not that all organelles exist as irreversible steady states, that every protein complex is a pleomorphic ensemble, and so on. It is rather that a become apparent that cells lack all four characteristic properties of machines that were identified in the introduction. First, once the crucial role that self-organization plays in shaping the cellular architecture is acknowledged, it is difficult to uphold the idea that the spatiotemporal arrangement of the parts of a cell obeys a predetermined blueprint or design, as it does in a machine. Second, the conformational flexibility of most cellular constituents and the functional promiscuity they exhibit shows that a cell’s operation is not as tightly constrained by its structural configuration as it is in a machine. Third, whereas a machine performs its function by precisely following a predefined sequence of steps, a cell can arrive at a particular end in a variety of ways: it can recruit different kinds of molecules to the same functionor the same kind of molecule to different functions—depending on the conditions it finds itself in. And fourth, a cell cannot be broken down into parts without jeopardizing its structural integrity in the way that every machine can. Cellular components form deeply intertwined, ever-changing networks of interactions that cannot be individually dissected without sacrificing the organization of the whole. “Cells are not engineered systems of discrete, interacting computational components, naturally yielding to compositional analysis” (Melham, 2013, p. 134), which is why they cannot be fully explained reductionistically; and neither do they operate deterministically, which is why their behaviour cannot be perfectly predicted. Monod was wrong. The cell is not a machine, but something altogether different—something more interesting yet also more unruly. It is a bounded, self-maintaining, steady-state organization of interconnected and interdependent processes; an integrated, dynamically stable, multi-scale system of conjugated fluxes collectively displaced from thermodynamic equilibrium. Given its precarious nature, the cell is constantly having to negotiate a trade-off between structural stability and functional flexibility: too much rigidity compromises physiological adaptability, and too much promiscuity compromises metabolic efficiency. The cell accomplishes this by continuously turning over and reorganizing its constituents into different macromolecular complexes with diverse functional capabilities, which assemble and disassemble in order to meet the ever-changing demands of the environment. The permanent stochastic shuffling of molecules inside the cell and their opportunistic associations to form transient functional ensembles in response to intracellular and extracellular cues provides fast and robust solutions to the adaptive problems faced by the cell in a way that strikes an optimal balance between efficacy and plasticity (Misteli, 2001b; Kurakin, 2009). Although this view of the cell has only come to the fore very recently, it is rather surprising to find that the theoretical principles that underlie it, as well as the empirical findings that support it, are not new at all. General denunciations of the MCC go back well over a century (e.g. Haldane, 1884), and even the recent empirical discoveries in each of the four domains I have examined in this paper have unmistakeable historical precedents. For instance, in the first half of the twentieth century it was not unusual for biochemists to describe the cell and its ostensibly solid and rigid contents in terms of streams, fluxes, and other processes (see Gilbert, 1982; Nicholson, 2018). A particularly visionary characterization of the dynamicity of the cellular architecture was offered by Bertavery large number of cellular and molecular phenomena that were traditionally interpreted in terms that support the MCC are now being explained in terms that directly oppose it. It is also worth mentioning that the various MCC-derived characterizations and their alternatives I have considered (and which I summarized for contrastive purposes in the tables included at the end of each section) may in some cases represent idealizations: two opposite extremes of a spectrum of actual positions. I already hinted that this might be the case for the ongoing dispute between power-stroke and Brownian ratchet models of intracellular transport.  lanffy, who was one of the first theoretical biologists (though today he is better known as the founder of general systems theory):  Formations such as the nuclear spindle, the Golgi apparatus, and the like appear as structures when we have them before us in a fixed and stained microscopic preparation. However, if we consider them in their changes in time, they are a manifestation of processes at the chemical and colloidal levels, quasistationary states that last for a while but soon undergo changes or disappear. (Bertalanffy, 1952, p. 136)  Challenges to the undue emphasis on the structure and specificity of proteins are likewise nothing new. The first reports of proteins with disordered structural domains date back to the 1950s (Karush, 1950; Jirgensons, 1958), and some hypotheses regarding the substrate ambiguity and catalytic promiscuity of metabolic enzymes are over forty years old (Jensen, 1976). Similarly, the suggestion that a microscopic ratchet might be able to harness the energy of Brownian motion to generate directed movement was carefully explored by Feynman in his physics lectures more than half a century ago (Feynman et al., 1963). Moreover, experimental evidence for the stochastic nature of cellular behaviour goes back six decades (Novick and Weiner, 1957), and the heterogeneity of isogenic cell populations was already noticed in the 1970s (Spudich and Koshland, 1976). Nevertheless, all of these ideas and observations remained severely neglected for many years. Only in the last two decades have they begun to receive widespread attention—mostly because the adoption of novel experimental methods has served to empirically substantiate them, making them impossible to ignore. But what is perhaps most surprising of all is that even though one would be hard-pressed to find a molecular biologist today that would dispute the fact that the cell is an open system far from equilibrium, or that because of its microscopic size the effects of stochastic fluctuations on its operation cannot be overlooked, many continue to explain cellular and molecular phenomena in the terms of classical mechanics, equilibrium thermodynamics, and mechanical and electronic engineering—that is to say, in terms of principles and concepts that are fundamentally at odds with the physical nature of the cell. This curious refusal of many researchers to accept, or even seriously consider, the new view of the cell that is arising is likely to be due to several factors. One might be that the new view is less intuitive than the MCC. The MCC, after all, draws on our everyday familiarity with machines. It is almost ‘natural’ for us to interpret everything in mechanical or engineering terms because such interpretations accord well with our experience of the familiar macroscopic physical world that we (and our machines) inhabit. Consequently, confronted with a microscopic entity such as a cell, “[t]he challenge for researchers is to look beyond our usual engineering principles and to appreciate the less familiar logic of biological organization.” (Glick, 2007, p. 132). Another factor that may help account for the reluctance of some researchers to endorse the new view is that it appears to make the cell a harder object to study than the MCC. Viewing the cell as a machine allows us to think of its organization in terms of modular, solid-state circuits that can be approached reductionistically, and it also gives us the confidence to expect that when we eventually work out how all of the cell’s parts fit together, we will be able to completely predict its behaviour. If, on the other hand, we view the cell as a highly integrated, self-organizing, fluid system composed of densely interconnected processes ever-subject to stochastic fluctuations, we no longer have reasons to suppose that achieving such epistemic goals is even possible, let alone feasible. The stark contrast between these two outlooks is exemplified by their strikingly different ways of understanding causation in the cell (Bizzarri et al., 2019), and it serves to explain why some
researchers find it easier than others to obtain funding and publish their work. As Mayer et al. point out:  It is much easier to write and publish a paper suggesting Protein X is necessary for transmitting a signal from A to B, than one showing that Protein X is one of many potential components of a heterogeneous ensemble of signaling complexes that together couple A to B. (Mayer et al., 2009, p. 81.6)  A further factor could be that accepting the new view of the cell requires us to adopt, and maybe also develop, concepts that fall outside the remit of the conventional molecular biology toolbox. It requires us—among other things—to seriously consider how the ideas of non-equilibrium thermodynamics and complexity theory, and even those of condensed matter physics and quantum mechanics, may be brought to bear on the interpretation and explanation of the phenomena we investigate, and this might not be agreeable to all researchers, many of whom appear to show little appetite for theoretical considerations—or, worse still, assume that they can proceed in the absence of theory altogether. Despite all of this, the advantages of embracing the new view of the cell are legion. Most importantly, the new view gives us a systematic and internally consistent interpretive framework capable of making theoretical sense of a multitude of empirical findings that appear paradoxical and almost inexplicable when viewed through the traditional lens of the MCC. Reports of self-organizing organelles, liquid-like macromolecular assemblies, fuzzy signalling complexes, moonlighting proteins, non-mechanical motors, orderfrom-disorder processes, non-genetic heterogeneity, and cell individuality seem totally baffling from the perspective of the MCC, but they can all be perfectly accommodated within the interpretive framework that is currently emerging. Findings which are confusing and unexpected within the old view become natural and expected within the new one. Ultimately, the current practice of overlooking some of the principles that govern the internal operation of the cell because they are unfamiliar, and of dismissing many of the cell’s distinctive properties because they are difficult to study, is likely to be a mistake. Only by confronting these head on can we hope one day to arrive at a theoretically satisfying understanding of what the cell is and how it functions as an integrated unit.
