---
dg-publish: true
tags: [ethics, lecture, note, university]
Course Code:
  - "[[CSC300]]"
Week: 5
Module:
  - "[[2 - Data, Privacy, and Surveillance]]"
Date: 2024-10-01
Quercus Page: https://q.utoronto.ca/courses/354160/pages/lecture-5-privacy?module_item_id=5960388
Slides/Notes:
Date created: Thu., Oct. 3, 2024, 4:35:22 pm
Date modified: Thu., Nov. 28, 2024, 4:13:28 pm
---

> [!goal]- Learning Objectives
>
> 1. Understand privacy from various perspectives
> 2. Understand the relationship between private and public
> 3. Understand the relationship between privacy and culture
> 4. understand the importance of privacy as an ethical standard

---

# Defining Privacy

- **Privacy**:
    - “Rightful control over information flow”
    - Sometimes, we want to spread information about us
    - Privacy $\neq$ keeping everything to yourself, hide all information
        - Rather, *control* over the information flow
            - What information are you sharing, and what information you are not sharing
    - Rightful?
        - e.g., Say that you have damaged someone’s property. You want to keep that a secret.
            - [p] Control over information flow
            - [c] ==Not rightful==
- Different ways of defining privacy varying with across **sociohistorical contexts**
    - People have different ideas of what they want to share or keep private
- Involves different *aspects* that may or may not be considered or address in certain contexts
    - e.g., Personal privacy from your family vs. Organizational privacy that seeks to keep corporate information confidential
- To enact privacy protection and consideration…
    - One needs to have a working **theory of privacy**
    - Know what it means for ==data/information to be considered private==
- Not all privacy rules are written down (in law)!
    - → There are *working theories* of privacy
    - i.e., In a particular context, you understand what information you can give and keep to yourself
    - Caused by social circumstances, norms, and people’s expectations

## Privacy Regulation: Culturally Universal or Culturally Specific?

> [!question]- How do you know what information should be kept confidential, and what information should be shared with others?
>
> - Learned from culture
>     - e.g., Family, school, TV, movies, friends
> - Culture actually details what is private info, what can be shared with whom

Is privacy culturally universal or culturally specific?

- **Culturally universal**
    - in that everyone has a *desire to regular* openness or closedness
    - to optimize the amount of privacy that one has
    - e.g., Every culture has processes by which they negotiate privacy
- **Culturally specific**
    - in that the psychological, behavioural, or technological mechanisms that regulate interaction will differ
    - e.g., Privacy request indicated with a closed door in one culture, sign in another

# Privacy as a Multimechanism Process

- Privacy regulation is a **dynamic, dialectic optimization process**
    - *Dialectic*:
        - It is a conversation between two people; dialogue
        - What information you share with someone depends on your relationship with that person
- **Dynamic dialectic**
    - Privacy is a ==boundary control process==
    - Alternation between being open and accessible and closing yourself off that *shifts* with circumstances
    - e.g., We have privacy mechanisms in our social media networks: Available, Away, DND, Offline → Change depending on how accessible you want yourself to be
- Privacy involves a ==network of behavioural mechanisms== that people use to achieve desired levels of social interaction
    - **Verbal/paraverbal behaviours**
        - Personal space/territoriality, culturally defined styles of responding
        - **Verbal**
            - In conversation: asking for privacy, or indicating that a conversation topic is private by using select word choice
        - **Paraverbal**
            - Using body language to indicate discomfort discussing private topics, using tech and artifacts in one’s environment to indicate privacy
                - e.g., a lock
    - **Operate as a system**
        - Involve interdependence and compensatory and substitutable action
        - Use different behaviour combinations to get desired privacy depending on circumstances
        - With advent of tech, there are more nonhuman agents that are not involved in the system and can be used to regulate
        - e.g., Indicate desire for privacy by leaving room, saying you don’t want to be disturbed, closing door, putting on headphones, etc. → all together indicate desire for privacy
- & Privacy regulation is a **dynamic, dialectic optimization process**
    - *Optimization process*
        - Ideal amount of privacy may shift from time to time (i.e., non-monotonic)
        - Deviations from the optimum can be personally unsatisfactory
        - Privacy is not a maximizing, monotonic process
        - i.e., Want max amount of info with the least amount shared
        - e.g., When making new friends because you don’t have any, might want less privacy to invite more people into your life
            - Once someone has friends → might be more private as new friends are no longer the goal

# Privacy as a Boundary Regulation; Unpacking Privacy for a Networked World

- “Networked world”
    - Everything is connected

<!-- break -->

- If privacy is selective control of the self $\implies$ involves a boundary regulation process where people optimize accessibility along a spectrum
- Generally, boundaries were *physical*, but with the advent of *information technologies*, physical boundaries are disrupted and so others must be considered

### Disclosure Boundary

- **Privacy and publicity**
    - Requires selective *disclosure of public information*
    - *Retention* of private information
- ==Maintaining privacy often requires disclosure==
    - i.e., You make some information public to protect other private information
    - e.g., Working PR for yourself → manage public to keep private secret
- ==Roles of disclosure can be used to limit rather than increase accessibility==
    - e.g., Professor setting up a website to limit strangers contacting
- ==Active participation in networked world requires disclosure==
    - e.g., Email, password, gender, phone number, nationality; Need to share to be apart of the network
    - ! Problem: When participation is not deliberate

### Identity Boundary

- **Self and other**
    - People often act as representatives or members of broader social groups that have set expectations to be incorporated into behaviours
- **Recipient design**
    - Actions/utterances are designed with respect to specific others
    - Self is constructed with respect to social arrangements
    - $\implies$Others are differentiated and treated differently
    - e.g., Employee contacting their employer: Formal language with respect using an email vs. contacting a friend (casual language over IM)

#### Interpretations of the Identity Boundary

- In technology, mutual access mediated by the tech:
    - You make assessments from a *representation that acts in proxy*
- Problem:
    - When what is conveyed is not when what is intended i.e., misunderstood
    - You control what information will flow from you to another person → Others are misinterpreting that info
    - e.g., Twitter arguments between social groups because one individual was critiquing something whereas another group thought it was an attack

### Temporal Boundary

- Say you share something on social media: I do not like pineapple on pizza
    - Couple years ago, you post a photo of you eating pineapple on pizza
    - Someone goes to your social media, finds that photo, brings to your attention
    - You will be challenged
    - You cannot write something on social media on a blank slate; everything is archived, not deleted permanently
    - Past is tied to you → How does that information affect you?
- **Past, present, and future**
    - Instances of disclosure are not isolated
    - Occur as an outcome of a sequence of events and stretch into the future
    - What you posted in the past can affect present
    - What you post now can affect your future
    - e.g., A tweet doesn’t go out into a blank account, preceding tweets set a context, future tweets will fit into the context you create with present tweets, but also into the broader social context - some prediction required abt. appropriateness
    - e.g., Share info with someone you consider a friend → Later, you are not friends; will this person misuse this information? $\implies$ **temporal boundary**
- ==Privacy management decision-making occurs in the context of a temporal sequence==
- Privacy management is also *mediated by what was in the past* and also what *may occur in the future* → management of tensions
    - Problem:
        - With information technologies, past interactions are often archived and easy to access
        - Future interactions will be similarly stored
        - Tensions that must be managed are magnified
        - e.g., Pulling up “receipts”/previous tweets in a Twitter argument to indicate that someone has a history that contradicts what they intend to convey or say in the current moment

### Example of These Boundaries

Consider sharing a photo from a family event on social media.

- Disclosure boundary:
    - How does privacy boundary change when you post the photo?
    - Does it make a previously private event public to distant family members or acquaintances?
    - For example, by sharing these moments, are you able to maintain a level of privacy in personal conversations, as distant relatives may feel updated and less likely to ask probing questions?
- Identity boundary:
    - How does this post reflect on your online identity?
    - Do you consider the diverse audience who might see this post, such as friends, colleagues, or older family members?
    - How does the generational aspect influence the content you choose to share?
    - For instance, do younger users post differently if their social media audience includes peers versus older family members?
- Temporal boundary:
    - Have you shared similar family moments in the past?
    - If so, how does this history influence the current post?
    - Does it feel like a continuation of your usual sharing habits, or does this post represent a new openness?
    - If this is the first time you’re sharing such a moment, what might this say about a shift in your comfort level with sharing personal experiences online?
    - How do you decide what platform you use?
        - If your family is on Facebook, you might post to something like Tiktok so they don’t see it → Control info flow
        - Generational aspect

# Privacy as Contextual Integrity

- ==Every information that gets parsed has (social) context==
    - Every context has some ==ethical expectation== from the participants
    - e.g., Conversation between friends; bi-directional
        - Expected that you do not talk about it outside of this setting
    - e.g., Conversation to doctor; uni-directional
        - Expected that doctor does not share info with someone else
    - e.g., Educational setting: Prof does not share grades with others
- Need to understand the context, what it demands from you, what kind of information flows

Consider a conversation between family during lunch.

- **Contextual integrity** means:
    - Information that was shared and discussed with family should not be leaked to the friend circle and vice versa
    - ==Need to be careful of what information you are sharing from one context to another==
- Scholars believe:
    - Every information has a context
    - Need to be loyal to that context
    - You don’t take one information from one context and share that with another context

<!-- break -->

- Many privacy theories still fail to adequately account for public surveillance and how it breaches privacy
    - e.g., Public records being stored online, consumer profiling/data mining, RFID tags
    - We try to reduce the information that is being shared with the government
        - Question of contextual integrity
        - Interactions between different contexts, e.g., household and income contexts
            - Why are we going to share this information with the government?
- Want to share the *bare minimum* information that the government will need to run the State
    - They might need to know: How many people live in this house
    - They don’t need to know: Favourite foods, etc.
    - Want to *minimize sharing info* to the government

**Three principles** should inform privacy regulation by other agents:

- & Limiting surveillance of citizens and use of information by agents of government
    - Governments often act overzealous in collecting/using information
    - Though some aspects of privacy are defended against government action
    - There should be a ==principled commitment== to limited government powers in the name of individual autonomy and liberty as the government has more power than the individual
- & Restricting access to sensitive/personal/private information
    - Societal standards of intimacy, sensitivity, or confidentiality deem some information personal and restricted
    - Connects to privacy being *[[#Privacy Regulation Culturally Universal or Culturally Specific?|culturally specific]]*
- & Prevent intrusion into places deemed private/personal
    - Certain spaces are considered personal and should be private from the government as well
    - Should be up to the discretion of the individual to invite the government into these spheres
    - Relates to privacy as a *[[#Privacy as a Boundary Regulation; Unpacking Privacy for a Networked World|boundary regulation]]*

> [!important]+ Determining the application of the principles means that boundary lines are ==neither static nor universal==.
>
> - Principles are presented as guidelines for how privacy should be regulated, especially in relation to powerful entities like governments
>     - Application of these principles is not fixed or universal
>     - Aligns with the earlier discussions about privacy being culturally specific and context-dependent
> - Principles also reflect the tension between individual privacy rights and the needs of society or government
>     - Suggest a balance where certain core aspects of privacy are protected while acknowledging that some information sharing is necessary for societal functioning

- **Contextual integrity**
    - Presented as a universal account of what does/does not warrant restrictive, privacy-motivated measures
    - A conceptual framework and not conditioned by time, location, etc.
- All arenas of life are governed by norms of informational flow
    - Happens in a context of place, politics, convention, and cultural expectation, shifting across the different arenas
    - Family setting vs. work setting: Norms that decide what information should be shared outside and whatnot
- Contexts/spheres allow for a *normative* account of privacy in terms of contextual integrity
- **Norms of Flow/Distribution**
    - Information that is appropriate or fitting to reveal in a *particular context* will not be appropriate in another
        - e.g., You will share information about physical condition in a medical context, but not to your barista
    - ==Appropriating information from one situation to another can constitute a violation==
    - Movement or transfer of info from one party to another will be unidirectional, bidirectional, or nonexistent
    - Will come with certain expectations about how one treats the information
        - Friendship: Flow = bidirectional, assumed to be confidential, at one’s own discretion
        - Medical settings: Patient expected to divulge info unidirectionally
    - ==Disrupting the flow or distribution can constitute a violation==

# Implementing Privacy

## Westin & the USA

- Alan Westin: “Privacy and Freedom,” “Databanks in a Free Society”
- Helped inform and prompt US to enact **internet privacy legislation** in 1960/70s
- Defined privacy as a legal right and ability to control which information we reveal about ourselves
- Argued that individuals should have *ultimate control* over their info
- Privacy should be an individual freedom

## General Data Protection Regulation

- Created in 2016, implemented in 2018
- **General Data Protection Regulation** (GDPR)
    - Requires organizations processing or collecting info on EU citizens to safeguard personal data and uphold privacy rights of those in EU territories
- Involves **seven principles of data protection** and **eight privacy rights**
    - Can be enforced with sanctions and fines
- Principles include:
    - ==Lawfulness, fairness and transparency==
    - ==Purpose limitation==
        - Process data for legitimate purposes specified
    - ==Data minimization==
        - Collect and process only as much data as absolutely necessary
    - ==Accuracy==
    - ==Storage limitation==
        - Only store personally identifying data for as long as necessary
        - As soon as you are done with the data, delete it
        - Store info anonymously → privacy is maintained
    - ==Integrity and confidentiality==
    - ==Accountability==

## FERPA

- **Family Educational Rights and Privacy Act** (FERPA)
    - US federal law
    - Protects privacy of student education records
    - Allows parents and students over 18 certain rights w.r.t education records
        - Ability to access, review, and request the correction of inaccurate information
    - e.g., Criminal charge, police want information on a student
    - Some “directory” information may still be disclosed by schools without consent

## HIPAA

- **Health Insurance Portability and Accountability Act** of 1996 (HIPAA)
    - Involved developing regulations to protect privacy and security of certain health information
    - Main goal: Protect privacy of individuals’ health info while allowing covered entities to adopt new tech to improve quality and efficiency of patient care

## PIPEDA

- **Personal Information Protection and Electronic Documents Act**
    - Applies to private-sector organizations across Canada that collect, use, or disclose personal info in the course of a commercial activity
    - Personal information includes any factual or subjective info, recorded or not, about an identifiable individual
        - Age, name, ID, income, ethnic origin, blood type
        - Opinions, evaluations, comments, social status, disciplinary actions
        - Employee files, credit records, loan records, medical records, dispute between consumer and a merchant, intentions

> [!question] Questions
>
> - Why might opinions, evaluations, or comments be considered personal information that deserves privacy (as this is listed in PIPEDA as protected personal information)
> - Why might educational grades and records be considered personal information that deserves privacy (as this is listed in FERPA as protected personal information)

# Privacy by Design

- Important to incorporate privacy considerations into design of technologies and information ecosystems
    - Different considerations might be relevant for different environments

## 7 Principles

Privacy by Design: The 7 Foundational Principles Implementation and Mapping of Fair Information Practices by Ann Cavoukian

1. Privacy has to be **proactive, not reactive**
    - Preventative, not remedial
    - To anticipate and prevent privacy invasion before it occurs, rather than remediating privacy risks, should be anticipated and prevented
2. Privacy as the **default** setting
    - Privacy of personal info should be protected and maintained as a default in given environment
    - Action should not be required on the part of the user to ensure privacy of their information
    - May choose to disclose it with further action
3. Privacy **embedded into design**
    - Privacy = core aspect of the application and be integrated into its functionality
    - Cannot be an extra consideration or add-on
    - Must be embedded in a holistic, integrated way
4. **Full functionality**
    - Positive-sum, not zero-sum
    - Privacy must accommodate all interests in a win-win situation vs. zero-sum manner that involves trade-offs
    - All requirements are optimized
    - Avoid false dichotomies such as privacy vs. security
        - Seek to optimize both
5. **End-to-end security**
    - Full lifecycle protecture
    - Privacy must be incorporated before any data collection, implementation, or manipulation occurs throughout the life cycle of the data
    - Data is to be collected and retained securely and destroyed at end of its life cycle
6. **Visibility and transparency**
    - Stakeholders must be assured that environment is operating according to stated promises
    - Visibility and transparency to ensure accountability and trust
7. **Respect for user privacy**
    - Keep it user-centric
    - Interests of individual use are to be maintained
        - *Consent* should be required for data collection, use, and disclosure
        - *Accuracy*: private info should be accurate and up-to-date as possible
        - *Access*: Users should be provided access to collected data and informed on its use
            - Should be able to challenge accuracy and completeness of the data
            - Allowed to amend it
